{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6888070,
          "sourceType": "datasetVersion",
          "datasetId": 3956862
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahatasham5/Breast_Cancer_Prognosis/blob/main/test_alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"color:yellow;display:inline-block;border-radius:5px;background-color:#007BA7;font-family:Nexa;overflow:hidden\"><p style=\"padding:15px;color:yellow;overflow:hidden;font-size:100%;letter-spacing:0.5px;margin:0\"><b> </b> Import Modules</p></div>"
      ],
      "metadata": {
        "id": "2fUBVSQuAFjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "gsnbRDhM7prX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "aZ8hZTB-7uJB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "def create_model(model_name, num_classes):\n",
        "    \"\"\"Creates a model based on the given name.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model (e.g., 'resnet50', 'vgg16', 'alexnet')\n",
        "        num_classes (int): Number of output classes for the model\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The initialized model.\n",
        "    \"\"\"\n",
        "    if model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=True)\n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=True)\n",
        "    elif model_name == 'alexnet':\n",
        "        model = models.alexnet(pretrained=True)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
        "\n",
        "    # Freeze pre-trained layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Replace final fully connected layer\n",
        "    num_ftrs = model.classifier[6].in_features  # Adjust index if necessary\n",
        "    model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "99dgdyIvm0lU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose your desired model\n",
        "model_name = 'alexnet'  # or 'vgg16', 'alexnet'\n",
        "num_classes = 1  # For binary classification\n",
        "\n",
        "# Create the model\n",
        "model = create_model(model_name, num_classes)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # Move the model to your device (CPU or GPU)\n",
        "\n",
        "# ... (your training and evaluation code)"
      ],
      "metadata": {
        "id": "vqv0he45nM4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec2feb2-2ded-4f74-84c8-eb578a3298f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 178MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcXWlLLzTHlM",
        "outputId": "073a91c5-6b04-4d34-f9cb-ebfffb330508"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxkmqWDx1txu",
        "outputId": "74c15f7f-ae2a-4161-e010-c55e00fe2dc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CSE/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uP28BdoUDG7",
        "outputId": "ff3773d0-aa2f-4536-f713-bce9f84bab67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqR0PLCp8Pl2",
        "outputId": "278563d7-19c4-46a8-a0e1-1c692680cf58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'Biglycan breast cancer dataset'\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the image to 224x224 for ResNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalization for ResNet\n",
        "])\n",
        "\n",
        "# Load your dataset\n",
        "dataset = datasets.ImageFolder(\"Biglycan breast cancer dataset\", transform=transform)\n",
        "\n",
        "# Splitting dataset into train and validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "b7btuRwA77qR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKYtD_LwUGIW",
        "outputId": "9222d4a2-9ca1-4b74-bd9b-7abb07e235d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'Biglycan breast cancer dataset'\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.classifier[6].parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "wXKGtWWQ8eLP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emfJsA6I8_7V",
        "outputId": "7347e29e-43b6-4f41-b9ef-c92c718465ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'Biglycan breast cancer dataset'\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the checkpoint file path\n",
        "checkpoint_path = 'model_checkpoint_alexnet.pth'\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.unsqueeze(1).type_as(outputs))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    # Save the checkpoint after each epoch\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': running_loss / len(train_loader)\n",
        "    }, checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiS5UQJ186CJ",
        "outputId": "d71562e7-8579-4c63-ed08-0b6e4375794d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6428489089012146\n",
            "Epoch 2, Loss: 0.6602249410417345\n",
            "Epoch 3, Loss: 0.6445890598826938\n",
            "Epoch 4, Loss: 0.6231973502371047\n",
            "Epoch 5, Loss: 0.6236704521709018\n",
            "Epoch 6, Loss: 0.6187152597639296\n",
            "Epoch 7, Loss: 0.6102357440524631\n",
            "Epoch 8, Loss: 0.629979219701555\n",
            "Epoch 9, Loss: 0.6040330727895101\n",
            "Epoch 10, Loss: 0.6122523612446256\n",
            "Epoch 11, Loss: 0.5915265878041586\n",
            "Epoch 12, Loss: 0.5873329506980048\n",
            "Epoch 13, Loss: 0.5864177081320021\n",
            "Epoch 14, Loss: 0.5936842958132426\n",
            "Epoch 15, Loss: 0.5724545452329848\n",
            "Epoch 16, Loss: 0.5712286631266276\n",
            "Epoch 17, Loss: 0.5831761194599999\n",
            "Epoch 18, Loss: 0.5796428057882521\n",
            "Epoch 19, Loss: 0.5590155588255988\n",
            "Epoch 20, Loss: 0.5617029004626803\n",
            "Epoch 21, Loss: 0.5731246537632413\n",
            "Epoch 22, Loss: 0.5632282727294498\n",
            "Epoch 23, Loss: 0.565015627278222\n",
            "Epoch 24, Loss: 0.560568587647544\n",
            "Epoch 25, Loss: 0.5600853496127658\n",
            "Epoch 26, Loss: 0.5686259137259589\n",
            "Epoch 27, Loss: 0.5579388671451144\n",
            "Epoch 28, Loss: 0.5495264927546183\n",
            "Epoch 29, Loss: 0.5330048667060004\n",
            "Epoch 30, Loss: 0.5536457002162933\n",
            "Epoch 31, Loss: 0.5464976893530952\n",
            "Epoch 32, Loss: 0.5467914475335015\n",
            "Epoch 33, Loss: 0.5362196630901761\n",
            "Epoch 34, Loss: 0.5338325699170431\n",
            "Epoch 35, Loss: 0.5416067971123589\n",
            "Epoch 36, Loss: 0.5553799569606781\n",
            "Epoch 37, Loss: 0.538763142294354\n",
            "Epoch 38, Loss: 0.5371896392769284\n",
            "Epoch 39, Loss: 0.5236063632700179\n",
            "Epoch 40, Loss: 0.5223074654738108\n",
            "Epoch 41, Loss: 0.5240157511499193\n",
            "Epoch 42, Loss: 0.5431374543242984\n",
            "Epoch 43, Loss: 0.5170627799299028\n",
            "Epoch 44, Loss: 0.547362529569202\n",
            "Epoch 45, Loss: 0.5251629882388644\n",
            "Epoch 46, Loss: 0.5273193650775485\n",
            "Epoch 47, Loss: 0.515654080443912\n",
            "Epoch 48, Loss: 0.5447358621491326\n",
            "Epoch 49, Loss: 0.5241770115163591\n",
            "Epoch 50, Loss: 0.5168381200896369\n",
            "Epoch 51, Loss: 0.5346798035833571\n",
            "Epoch 52, Loss: 0.5287590622901917\n",
            "Epoch 53, Loss: 0.5109878877798716\n",
            "Epoch 54, Loss: 0.5052604642179277\n",
            "Epoch 55, Loss: 0.5048715273539225\n",
            "Epoch 56, Loss: 0.5044498609171973\n",
            "Epoch 57, Loss: 0.5027449826399485\n",
            "Epoch 58, Loss: 0.5039838155110677\n",
            "Epoch 59, Loss: 0.5020132892661624\n",
            "Epoch 60, Loss: 0.5017804072962867\n",
            "Epoch 61, Loss: 0.49499379595120746\n",
            "Epoch 62, Loss: 0.49865567021899754\n",
            "Epoch 63, Loss: 0.5033890340063307\n",
            "Epoch 64, Loss: 0.5164115031560262\n",
            "Epoch 65, Loss: 0.48781245946884155\n",
            "Epoch 66, Loss: 0.4968051148785485\n",
            "Epoch 67, Loss: 0.5123076505131192\n",
            "Epoch 68, Loss: 0.48764971892038983\n",
            "Epoch 69, Loss: 0.48103924592336017\n",
            "Epoch 70, Loss: 0.49067657192548114\n",
            "Epoch 71, Loss: 0.4906986355781555\n",
            "Epoch 72, Loss: 0.49976300530963474\n",
            "Epoch 73, Loss: 0.5104597873157926\n",
            "Epoch 74, Loss: 0.48930785722202724\n",
            "Epoch 75, Loss: 0.4899165895250108\n",
            "Epoch 76, Loss: 0.4867595003710853\n",
            "Epoch 77, Loss: 0.4746908313698239\n",
            "Epoch 78, Loss: 0.48558950755331254\n",
            "Epoch 79, Loss: 0.5033999449676938\n",
            "Epoch 80, Loss: 0.47491846481959027\n",
            "Epoch 81, Loss: 0.48408861292733085\n",
            "Epoch 82, Loss: 0.46170859535535175\n",
            "Epoch 83, Loss: 0.4850229322910309\n",
            "Epoch 84, Loss: 0.46553538574112785\n",
            "Epoch 85, Loss: 0.4650554524527656\n",
            "Epoch 86, Loss: 0.4730325871043735\n",
            "Epoch 87, Loss: 0.4784066081047058\n",
            "Epoch 88, Loss: 0.48354213105307686\n",
            "Epoch 89, Loss: 0.471102817191018\n",
            "Epoch 90, Loss: 0.4640367925167084\n",
            "Epoch 91, Loss: 0.4711475604110294\n",
            "Epoch 92, Loss: 0.46607348654005265\n",
            "Epoch 93, Loss: 0.4494726128048367\n",
            "Epoch 94, Loss: 0.4723285966449314\n",
            "Epoch 95, Loss: 0.4423267940680186\n",
            "Epoch 96, Loss: 0.4543139768971337\n",
            "Epoch 97, Loss: 0.46495240926742554\n",
            "Epoch 98, Loss: 0.46780763732062447\n",
            "Epoch 99, Loss: 0.48402998513645595\n",
            "Epoch 100, Loss: 0.4655163884162903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo77SsrU-ITI",
        "outputId": "2b42af92-e3e7-4017-edd0-721d2f649d32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'Biglycan breast cancer dataset'\u001b[0m/   model_checkpoint_alexnet.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the checkpoint file path\n",
        "checkpoint_path = 'model_checkpoint_alexnet.pth'\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "start_epoch = checkpoint['epoch'] + 1\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "print(f\"Resuming training from epoch {start_epoch}, with loss: {loss}\")\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.unsqueeze(1).type_as(outputs))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    # Save the checkpoint after each epoch\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': running_loss / len(train_loader)\n",
        "    }, checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYFAWNVz-UCM",
        "outputId": "14ecf3ee-5dce-4c4e-ace1-89b8f3533a28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming training from epoch 100, with loss: 0.4655163884162903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load('model_checkpoint_alexnet.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "crBfjrJnMy-V",
        "outputId": "b62931b0-73ad-4e76-b5b4-ec8f32ead1a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for AlexNet:\n\tMissing key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.6.weight\", \"classifier.6.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cb35ff538c27>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the saved model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_checkpoint_alexnet.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AlexNet:\n\tMissing key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.6.weight\", \"classifier.6.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load('model_checkpoint_alexnet.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Optionally, you can also load the optimizer state and other saved data\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "eIhnmffoM5qJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.sigmoid(outputs) > 0.5\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate and print the evaluation metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(all_targets, np.array(all_preds).flatten()))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_targets, np.array(all_preds).flatten(), target_names=['Healthy', 'Cancerous']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GCHoGdJTSnC",
        "outputId": "f6fd42a4-d782-4203-d3a4-aaa04dcb9402"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[32  6]\n",
            " [11 19]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.74      0.84      0.79        38\n",
            "   Cancerous       0.76      0.63      0.69        30\n",
            "\n",
            "    accuracy                           0.75        68\n",
            "   macro avg       0.75      0.74      0.74        68\n",
            "weighted avg       0.75      0.75      0.75        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Apply sigmoid since we used BCEWithLogitsLoss\n",
        "        predicted_probs = torch.sigmoid(outputs)\n",
        "\n",
        "        # Convert probabilities to predicted class (0 or 1)\n",
        "        predicted = predicted_probs > 0.5\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.flatten() == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3YUQjo0TqDf",
        "outputId": "0910f10a-5f05-4888-ac84-736c35726bdc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.00%\n"
          ]
        }
      ]
    }
  ]
}